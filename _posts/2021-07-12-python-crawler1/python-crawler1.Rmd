---
title: urllib으로 웹페이지 추출 in python
description: |
  파이썬 urllib.request 모듈을 이용한 웹페이지 추출
author:
  - name: nackta
    url: {}
date: 07-12-2021
categories:
  - Python
  - Crawling
output:
  distill::distill_article:
    self_contained: false
    toc: true
 
---
# 1. 크롤러란?

크롤러 : 웹페이지의 하이퍼링크를 순회하면서 웹 페이지를 다운로드 하는 작업

스크레이핑 : 다운로드한 웹페이지에서 필요한 정보를 추출하는 작업

# 2. urllib으로 웹페이지 추출하기

```{python echo = T}
from urllib.request import urlopen
import sys
f = urlopen('https://news.daum.net/breakingnews/economic')
```

urlopen() 함수는 URL을 인자로 받아 HTTPResponse 자료형의 객체를 반환한다.

```{python echo = T}
encoding = f.info().get_content_charset(failobj="utf-8")
print('encoding:', encoding, file=sys.stderr)
```

HTTPResponse의 content-type을 참조하면 인코딩 방식을 알아낼 수 있다.

인코딩 방식이 설정되있지 않다면 자동으로 utf-8을 사용하도록 설정한다.
  
```{python}
text = f.read().decode(encoding)
# print(text) #너무 길어서 주석처리
```

.decode(인코딩방식)을 입력해주면 HTTPResponse에서 bytes 자료형이었던 문자열을 str 자료형으로 디코딩 해준다.

# 3. meta 태그에서 인코딩 방식 추출법

HTTPResponse의 content-type의 정보가 항상 맞지 않는 경우가 있다. 이럴땐 meta태그에서 명시된 인코딩 방식을 추출할 수 있다.
  
```{python}
import re
f = urlopen('https://news.daum.net/breakingnews/economic')
bytes_content = f.read()
```
 
일단 bytes 자료형을 변수에 저장한다.
  
```{python}
scanned_text = bytes_content[:1024].decode('ascii', errors='replace')
```
  
meta태그에서 인코딩 방식은 charset="~"형태로 명시되 있는데 HTML 앞부분에 적혀 있는 경우가 많다. 그래서 1024바이트 부분까지 슬라이싱 하여 ascii문자로 디코딩 한다. ascii범위 외 문자는 대체(replace)되어 예외가 없다.
  
```{python}
match = re.search(r'charset=["\']?([\w-]+)', scanned_text)
match.group(1)
```

정규 표현식을 통해 charset=값을 추출한다. 확인해보면 utf-8임을 알 수있다.
  
```{python}
if match:
    encoding = match.group(1)
else:
    encoding = 'utf-8'
    
text = bytes_content.decode(encoding)
# print(text)
```
 
만약 charset이 명시되지 않았다면 utf-8을 사용한다.

print(text)를 통해 html형식의 문자열을 확인할 수 있다.

