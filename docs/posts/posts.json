[
  {
    "path": "posts/2021-10-30-use-gdata-api/",
    "title": "공공데이터 포털 open API 이용하기",
    "description": "관세청 수출입실적 쉽게 수집하기",
    "author": [
      {
        "name": "nackta",
        "url": {}
      }
    ],
    "date": "2021-10-30",
    "categories": [
      "R",
      "Crawling"
    ],
    "contents": "\r\n\r\nContents\r\n공공데이터 포털의 open\r\nAPI\r\n관세청 수출입실적\r\nAPI 수집 코드의 흐름\r\nurl만들기\r\nurl을 이용하여 요청값\r\n받기\r\n데이터 프레임으로 정리\r\n함수 만들기\r\n\r\n\r\n공공데이터 포털의 open API\r\n공공데이터 포털에서 제공하는\r\nopen API가 7천여개 정도 있으며 해당 사이트에서는 이용자들이 API를 쉽게\r\n이용할 수 있도록 샘플코드를 다음과 같이 제공하고 있습니다.\r\n\r\n\r\n# install.packages(\"httr\")\r\n# \r\n# library(httr)\r\n# GET('http://openapi.customs.go.kr/openapi/service/newTradestatistics/getNitemtradeList?\r\n#     serviceKey=ServiceKey&searchBgnDe=201601&searchEndDe=201601&searchItemCd=0202&searchStatCd=US')\r\n\r\n\r\n\r\n위 코드는 사실 이용하기 힘듭니다… 그래서 새로운 방법으로 API수집을\r\n위한 코딩이 필요하죠. 이번 포스팅에서는 관세청 수출입실적 open API를\r\n수집하는 함수를 만들어보겠습니다.\r\n관세청 수출입실적\r\n관세청 수출입실적은 아래 그림처럼 시작년도월, 끝년도월, 품목코드,\r\n국가명을 요청하면 요청값에 맞는 수출입실적 데이터를 출력해주는\r\nAPI입니다.\r\n\r\nAPI 수집 코드의 흐름\r\nurl만들기\r\n요청하는 url를 확인해보면 다음과 같습니다.\r\nhttp://openapi.customs.go.kr/openapi/service/newTradestatistics/getNitemtradeList?\r\nserviceKey=ServiceKey&\r\nsearchBgnDe=201601&\r\nsearchEndDe=201601&\r\nsearchItemCd=0202&\r\nsearchStatCd=US\r\n굵은 글씨만 바꿔서 url를 만들 수 있도록 하는 것이 첫번째 목표입니다.\r\n각 요청값을 인자로 받아 요청url을 만들어주는 함수를 만듭니다.\r\n\r\n\r\none_getNitemtradeList <- function(ServiceKey, startpoint, endpoint, hscode, country){\r\n  \r\n    url <- paste0(\"http://openapi.customs.go.kr/openapi/service/newTradestatistics/getNitemtradeList?ServiceKey=\",\r\n                  ServiceKey,\r\n                  \r\n                  \"&searchBgnDe=\", startpoint,\r\n                  \"&searchEndDe=\", endpoint,\r\n                  \"&searchItemCd=\", hscode,\r\n                  \"&searchStatCd=\", country)\r\n    return(url)\r\n}\r\n\r\nmyurl <- one_getNitemtradeList('ServiceKey', '201601', '201612', '0202', 'US')\r\nmyurl\r\n\r\n\r\n[1] \"http://openapi.customs.go.kr/openapi/service/newTradestatistics/getNitemtradeList?ServiceKey=ServiceKey&searchBgnDe=201601&searchEndDe=201612&searchItemCd=0202&searchStatCd=US\"\r\n\r\n여기서 paste0() 함수는 각 문자열을 빈칸없이 이어서 출력해줍니다.\r\n\r\n\r\npaste0('a', 'b', 'c')\r\n\r\n\r\n[1] \"abc\"\r\n\r\nurl을 이용하여 요청값 받기\r\n공공데이터포털에서 제공하는 API중 상당부분이 XML형식으로 제공하고\r\n있습니다. 관세청 데이터도 마찬가지 입니다. 그러므로 xml파일을 읽기위한\r\n“xml2”패키지를 사용해보겠습니다. 저는 블로그에 서비스키를 노출할 수\r\n없으므로 xml파일로 저장하여 불러오겠습니다. 실제로는 read_xml(myurl)을\r\n실행시키면 됩니다.\r\n\r\n\r\nlibrary(xml2)\r\n# read_xml(myurl)\r\nmyxml <- read_xml('myurl.xml')\r\nmyxml\r\n\r\n\r\n{xml_document}\r\n<response>\r\n[1] <header>\\n  <resultCode>00<\/resultCode>\\n  <resultMsg>NORMAL SE ...\r\n[2] <body>\\n  <items>\\n    <item>\\n      <balPayments>-93603291<\/ba ...\r\n\r\nxml을 쉽게 읽을 수 있을때까지 하위 노드로 이동합니다.\r\n1번째 하위노드\r\n\r\n\r\nlibrary(dplyr)\r\nmyxml %>% xml_children()\r\n\r\n\r\n{xml_nodeset (2)}\r\n[1] <header>\\n  <resultCode>00<\/resultCode>\\n  <resultMsg>NORMAL SE ...\r\n[2] <body>\\n  <items>\\n    <item>\\n      <balPayments>-93603291<\/ba ...\r\n\r\n2번째 하위노드\r\n\r\n\r\nmyxml %>% xml_children() %>% xml_children()\r\n\r\n\r\n{xml_nodeset (3)}\r\n[1] <resultCode>00<\/resultCode>\r\n[2] <resultMsg>NORMAL SERVICE.<\/resultMsg>\r\n[3] <items>\\n  <item>\\n    <balPayments>-93603291<\/balPayments>\\n   ...\r\n\r\n3번째 하위노드\r\n\r\n\r\nxml_expimp <- myxml %>% xml_children() %>% xml_children() %>% xml_children\r\nxml_expimp\r\n\r\n\r\n{xml_nodeset (13)}\r\n [1] <item>\\n  <balPayments>-93603291<\/balPayments>\\n  <expDlr>1508 ...\r\n [2] <item>\\n  <balPayments>-49505329<\/balPayments>\\n  <expDlr>1691 ...\r\n [3] <item>\\n  <balPayments>-42048571<\/balPayments>\\n  <expDlr>0<\/e ...\r\n [4] <item>\\n  <balPayments>-47107245<\/balPayments>\\n  <expDlr>0<\/e ...\r\n [5] <item>\\n  <balPayments>-63364870<\/balPayments>\\n  <expDlr>0<\/e ...\r\n [6] <item>\\n  <balPayments>-63149821<\/balPayments>\\n  <expDlr>3069 ...\r\n [7] <item>\\n  <balPayments>-57094516<\/balPayments>\\n  <expDlr>0<\/e ...\r\n [8] <item>\\n  <balPayments>-81466942<\/balPayments>\\n  <expDlr>0<\/e ...\r\n [9] <item>\\n  <balPayments>-70583966<\/balPayments>\\n  <expDlr>0<\/e ...\r\n[10] <item>\\n  <balPayments>-75331115<\/balPayments>\\n  <expDlr>0<\/e ...\r\n[11] <item>\\n  <balPayments>-62108095<\/balPayments>\\n  <expDlr>0<\/e ...\r\n[12] <item>\\n  <balPayments>-44762813<\/balPayments>\\n  <expDlr>0<\/e ...\r\n[13] <item>\\n  <balPayments>-750126574<\/balPayments>\\n  <expDlr>626 ...\r\n\r\n위처럼 3번째 하위 노드로 내려가면 출력값변수명> 형태의\r\n출력값에 접근할 수 있습니다. 이제 데이터 프레임 형태로 정리하는 일만\r\n남았습니다.\r\n데이터 프레임으로 정리\r\nxml_expimp의 첫번째 노드를 살펴보면 각 출력값마다 ’/’이 포함되 있는\r\n규칙을 발견할 수 있습니다.\r\n\r\n\r\nxml_expimp[1]\r\n\r\n\r\n{xml_nodeset (1)}\r\n[1] <item>\\n  <balPayments>-93603291<\/balPayments>\\n  <expDlr>15082 ...\r\n\r\n이를 xml_find_all()과 정규표현식을 이용해 다음과 같이 정리할 수\r\n있습니다.\r\n\r\n\r\ntemp_row <- xml_find_all(xml_expimp[1], './*')\r\ntemp_row\r\n\r\n\r\n{xml_nodeset (10)}\r\n [1] <balPayments>-93603291<\/balPayments>\r\n [2] <expDlr>150822<\/expDlr>\r\n [3] <expWgt>18003<\/expWgt>\r\n [4] <hsCd>0202<\/hsCd>\r\n [5] <impDlr>93754113<\/impDlr>\r\n [6] <impWgt>14809834<\/impWgt>\r\n [7] <statCd>US<\/statCd>\r\n [8] <statCdCntnKor1>미국<\/statCdCntnKor1>\r\n [9] <statKor>쇠고기(냉동한 것으로 한정한다)&#13;\\n<\/statKor>\r\n[10] <year>2016.01<\/year>\r\n\r\n이제 출력명과 출력값을 나눌 차례입니다. xml_name()통해 을\r\n추출하고, xml_text()통해 출력값을 추출할 수 있습니다.\r\n\r\n\r\ntemp_row %>% xml_name()\r\n\r\n\r\n [1] \"balPayments\"    \"expDlr\"         \"expWgt\"        \r\n [4] \"hsCd\"           \"impDlr\"         \"impWgt\"        \r\n [7] \"statCd\"         \"statCdCntnKor1\" \"statKor\"       \r\n[10] \"year\"          \r\n\r\n\r\n\r\ntemp_row %>% xml_text()\r\n\r\n\r\n [1] \"-93603291\"                         \r\n [2] \"150822\"                            \r\n [3] \"18003\"                             \r\n [4] \"0202\"                              \r\n [5] \"93754113\"                          \r\n [6] \"14809834\"                          \r\n [7] \"US\"                                \r\n [8] \"미국\"                              \r\n [9] \"쇠고기(냉동한 것으로 한정한다)\\r\\n\"\r\n[10] \"2016.01\"                           \r\n\r\n이를 tibble을 사용하여 데이터 프레임 형태로 정리하면,\r\n\r\n\r\nlibrary(tibble)\r\ntibble(idx = 1, key = temp_row %>% xml_name(), value = temp_row %>% xml_text())\r\n\r\n\r\n# A tibble: 10 x 3\r\n     idx key            value                               \r\n   <dbl> <chr>          <chr>                               \r\n 1     1 balPayments    \"-93603291\"                         \r\n 2     1 expDlr         \"150822\"                            \r\n 3     1 expWgt         \"18003\"                             \r\n 4     1 hsCd           \"0202\"                              \r\n 5     1 impDlr         \"93754113\"                          \r\n 6     1 impWgt         \"14809834\"                          \r\n 7     1 statCd         \"US\"                                \r\n 8     1 statCdCntnKor1 \"미국\"                              \r\n 9     1 statKor        \"쇠고기(냉동한 것으로 한정한다)\\r\\n\"\r\n10     1 year           \"2016.01\"                           \r\n\r\n이를 모든 노드에 적용하여 tibble로 만들어 줍니다.\r\n\r\n\r\ntmp1 <- lapply(seq_along(xml_expimp),\r\n               function(x){\r\n                 temp_row <- xml_find_all(xml_expimp[x], './*')\r\n                 tibble(idx = x,\r\n                        key = temp_row %>% xml_name(),\r\n                        value = temp_row %>% xml_text()\r\n                 ) %>% return()\r\n                 }\r\n               )\r\ntmp1 %>% head(3)\r\n\r\n\r\n[[1]]\r\n# A tibble: 10 x 3\r\n     idx key            value                               \r\n   <int> <chr>          <chr>                               \r\n 1     1 balPayments    \"-93603291\"                         \r\n 2     1 expDlr         \"150822\"                            \r\n 3     1 expWgt         \"18003\"                             \r\n 4     1 hsCd           \"0202\"                              \r\n 5     1 impDlr         \"93754113\"                          \r\n 6     1 impWgt         \"14809834\"                          \r\n 7     1 statCd         \"US\"                                \r\n 8     1 statCdCntnKor1 \"미국\"                              \r\n 9     1 statKor        \"쇠고기(냉동한 것으로 한정한다)\\r\\n\"\r\n10     1 year           \"2016.01\"                           \r\n\r\n[[2]]\r\n# A tibble: 10 x 3\r\n     idx key            value                               \r\n   <int> <chr>          <chr>                               \r\n 1     2 balPayments    \"-49505329\"                         \r\n 2     2 expDlr         \"169130\"                            \r\n 3     2 expWgt         \"18051\"                             \r\n 4     2 hsCd           \"0202\"                              \r\n 5     2 impDlr         \"49674459\"                          \r\n 6     2 impWgt         \"8592190\"                           \r\n 7     2 statCd         \"US\"                                \r\n 8     2 statCdCntnKor1 \"미국\"                              \r\n 9     2 statKor        \"쇠고기(냉동한 것으로 한정한다)\\r\\n\"\r\n10     2 year           \"2016.02\"                           \r\n\r\n[[3]]\r\n# A tibble: 10 x 3\r\n     idx key            value                               \r\n   <int> <chr>          <chr>                               \r\n 1     3 balPayments    \"-42048571\"                         \r\n 2     3 expDlr         \"0\"                                 \r\n 3     3 expWgt         \"0\"                                 \r\n 4     3 hsCd           \"0202\"                              \r\n 5     3 impDlr         \"42048571\"                          \r\n 6     3 impWgt         \"7274029\"                           \r\n 7     3 statCd         \"US\"                                \r\n 8     3 statCdCntnKor1 \"미국\"                              \r\n 9     3 statKor        \"쇠고기(냉동한 것으로 한정한다)\\r\\n\"\r\n10     3 year           \"2016.03\"                           \r\n\r\n각 tibble을 bind_rows()를 이용하여 하나의 tibble로 만들어줍니다.\r\n\r\n\r\ntmp2 <- bind_rows(tmp1)\r\ntmp2\r\n\r\n\r\n# A tibble: 130 x 3\r\n     idx key            value                               \r\n   <int> <chr>          <chr>                               \r\n 1     1 balPayments    \"-93603291\"                         \r\n 2     1 expDlr         \"150822\"                            \r\n 3     1 expWgt         \"18003\"                             \r\n 4     1 hsCd           \"0202\"                              \r\n 5     1 impDlr         \"93754113\"                          \r\n 6     1 impWgt         \"14809834\"                          \r\n 7     1 statCd         \"US\"                                \r\n 8     1 statCdCntnKor1 \"미국\"                              \r\n 9     1 statKor        \"쇠고기(냉동한 것으로 한정한다)\\r\\n\"\r\n10     1 year           \"2016.01\"                           \r\n# ... with 120 more rows\r\n\r\nspread()이용하여 출력명을 기준으로 출력값을 정리해줍니다. 이렇게 하면\r\n원하는 데이터 프레임 형태의 값을 얻을 수 있습니다.\r\n\r\n\r\nlibrary(tidyr)\r\nspread(tmp2, key = 'key', value = 'value')\r\n\r\n\r\n# A tibble: 13 x 11\r\n     idx balPayments expDlr expWgt hsCd  impDlr    impWgt    statCd\r\n   <int> <chr>       <chr>  <chr>  <chr> <chr>     <chr>     <chr> \r\n 1     1 -93603291   150822 18003  0202  93754113  14809834  US    \r\n 2     2 -49505329   169130 18051  0202  49674459  8592190   US    \r\n 3     3 -42048571   0      0      0202  42048571  7274029   US    \r\n 4     4 -47107245   0      0      0202  47107245  8142437   US    \r\n 5     5 -63364870   0      0      0202  63364870  10805844  US    \r\n 6     6 -63149821   306916 21418  0202  63456737  11040639  US    \r\n 7     7 -57094516   0      0      0202  57094516  9980159   US    \r\n 8     8 -81466942   0      0      0202  81466942  14426608  US    \r\n 9     9 -70583966   0      0      0202  70583966  13198366  US    \r\n10    10 -75331115   0      0      0202  75331115  13838084  US    \r\n11    11 -62108095   0      0      0202  62108095  11295626  US    \r\n12    12 -44762813   0      0      0202  44762813  8155284   US    \r\n13    13 -750126574  626868 57472  -     750753442 131559098 -     \r\n# ... with 3 more variables: statCdCntnKor1 <chr>, statKor <chr>,\r\n#   year <chr>\r\n\r\n함수 만들기\r\n지금까지 했던 과정을 종합하여 함수로 만듭니다. 공공데이터 포털에서\r\n서비스키만 발급받는다면 사용할 수 있습니다!\r\n\r\n\r\none_getNitemtradeList <- function(ServiceKey, startpoint, endpoint, hscode, country){\r\n     \r\n    url <- paste0(\"http://openapi.customs.go.kr/openapi/service/newTradestatistics/\r\n                  getNitemtradeList?ServiceKey=\", ServiceKey,\r\n                  \"&searchBgnDe=\", startpoint,\r\n                  \"&searchEndDe=\", endpoint,\r\n                  \"&searchItemCd=\", hscode,\r\n                  \"&searchStatCd=\", country)\r\n    \r\n    xml_expimp <- read_xml(url) %>% xml_children() %>% xml_children() %>% xml_children()\r\n    \r\n    tmp1 <- lapply(seq_along(xml_expimp),\r\n                   function(x){\r\n                       temp_row <- xml_find_all(xml_expimp[x], './*')\r\n                       tibble(idx = x,\r\n                              key = temp_row %>% xml_name(),\r\n                              value = temp_row %>% xml_text()\r\n                       ) %>% return()\r\n                   }\r\n    )\r\n    \r\n    tmp2 <- bind_rows(tmp1)\r\n  \r\n    spread(tmp2, key = 'key', value = 'value') %>% return()\r\n}\r\n\r\n# one_getNitemtradeList(ServiceKey, \"201001\", \"201012\", \"3304\", \"US\")\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-10-30-use-gdata-api/images/gdata.png",
    "last_modified": "2022-05-16T15:11:27+09:00",
    "input_file": {},
    "preview_width": 215,
    "preview_height": 150
  },
  {
    "path": "posts/2021-07-18-python-crawler3/",
    "title": "RSS 이용하기",
    "description": "RSS을 통해 XML파일 스크레이핑.",
    "author": [
      {
        "name": "nackta",
        "url": {}
      }
    ],
    "date": "2021-07-18",
    "categories": [
      "Python",
      "Crawling"
    ],
    "contents": "\r\n\r\nContents\r\nXML(RSS) 스크레이핑\r\n\r\nXML(RSS) 스크레이핑\r\n몇몇 웹사이트는 빈번하게 변하는 정보를 사용자에게 제공하기 위해\r\nRSS라는 서비스를 제공한다. 이 서비스를 사용하면 XML형식의 정보를\r\n실시간으로 얻을 수 있게된다.\r\n이번엔 기상청 RSS를 추출해보겠다. RSS 링크는 다음과 같다.\r\nhttp://www.kma.go.kr/weather/forecast/mid-term-rss3.jsp?stnId=146\r\n\r\nfrom xml.etree import ElementTree\r\nfrom urllib.request import urlopen\r\nf = urlopen('http://www.kma.go.kr/weather/forecast/mid-term-rss3.jsp?stnId=146')\r\nxml_data = f.read().decode('utf-8')\r\n\r\n\r\nroot = ElementTree.fromstring(xml_data)\r\nroot\r\n<Element 'rss' at 0x000000002EB613B0>\r\n\r\npandas의 데이터프레임 형태로 일시, 최저, 최고, 날씨 정보를\r\n추출한다.\r\n원하는 정보를 얻기 위해 xml이 어떤 형식으로 이루어져 있는지\r\n확인한다.\r\nchannel/item/description/body/location/data에 원하는 정보가 있다.\r\n\r\nimport pandas as pd\r\ndatalist = []\r\nfor item in root.findall('channel/item/description/body/location/data'):\r\n    # find() 메서드로 element 탐색, text 속성으로 값을 추출\r\n    tm_ef = item.find('tmEf').text\r\n    tmn = item.find('tmn').text\r\n    tmx = item.find('tmx').text\r\n    wf = item.find('wf').text\r\n    data = pd.DataFrame({\r\n        '일시':[tm_ef],\r\n        '최저기온':[tmn],\r\n        '최고기온':[tmx],\r\n        '날씨':[wf],\r\n    })\r\n    datalist.append(data)\r\nweather = pd.concat(datalist)\r\nweather  \r\n                  일시 최저기온 최고기온    날씨\r\n0   2022-05-18 00:00   14   27    맑음\r\n0   2022-05-18 12:00   14   27    맑음\r\n0   2022-05-19 00:00   14   27    맑음\r\n0   2022-05-19 12:00   14   27  구름많음\r\n0   2022-05-20 00:00   14   27  구름많음\r\n..               ...  ...  ...   ...\r\n0   2022-05-22 00:00   14   26    맑음\r\n0   2022-05-22 12:00   14   26    맑음\r\n0   2022-05-23 00:00   15   26    맑음\r\n0   2022-05-24 00:00   15   26    맑음\r\n0   2022-05-25 00:00   15   26  구름많음\r\n\r\n[182 rows x 4 columns]\r\n\r\n하지만 이 날씨가 어느지역의 날씨인지 알 수가 없다. 지역별로 다시\r\n정리해봤다.\r\n\r\ncitylist = []\r\nfor item in root.findall('channel/item/description/body/location'):\r\n  city = item.find('city').text\r\n  citylist = citylist + ([city]*13)\r\nweather['지역'] = citylist\r\n\r\n\r\n\r\nlibrary(reticulate)\r\nknitr::kable(head(py$weather))\r\n\r\n\r\n일시\r\n최저기온\r\n최고기온\r\n날씨\r\n지역\r\n2022-05-18 00:00\r\n14\r\n27\r\n맑음\r\n전주\r\n2022-05-18 12:00\r\n14\r\n27\r\n맑음\r\n전주\r\n2022-05-19 00:00\r\n14\r\n27\r\n맑음\r\n전주\r\n2022-05-19 12:00\r\n14\r\n27\r\n구름많음\r\n전주\r\n2022-05-20 00:00\r\n14\r\n27\r\n구름많음\r\n전주\r\n2022-05-20 12:00\r\n14\r\n27\r\n구름많음\r\n전주\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-07-18-python-crawler3/images/rss.png",
    "last_modified": "2022-05-16T00:26:33+09:00",
    "input_file": {},
    "preview_width": 352,
    "preview_height": 143
  },
  {
    "path": "posts/2021-07-17-python-crawler2/",
    "title": "정규표현식으로 스크레이핑",
    "description": "re모듈을 익히고 정규표현식으로 html파일 접근하기",
    "author": [
      {
        "name": "nackta",
        "url": {}
      }
    ],
    "date": "2021-07-17",
    "categories": [
      "Python",
      "Crawling"
    ],
    "contents": "\r\n\r\nContents\r\nre모듈\r\n정규표현식으로\r\n스크레이핑\r\n\r\n정규표현식은 특정한 문자열의 집합을 표현하는 방법이다. 이 방법을 통해\r\nhtml에서 원하는 정보만을 추출 할 수 있다.\r\nre모듈\r\nre모듈 안에는 정규표현식과 관련된 함수를 제공한다.\r\n\r\nimport re\r\n\r\nre.search(“정규표현식”, 문자열) 함수는 문자열이 정규표현식에 맞는지\r\n확인해준다. 맞는 경우 match객체를 반환하고 맞지 않는 경우 None을\r\n반환한다.\r\n\r\n#a 그리고 모든 문자 중 한가지가 0개 이상 포함하고 다음 c인 문자열\r\nre.search(r'a.*c', 'abc123DEF')\r\n<re.Match object; span=(0, 3), match='abc'>\r\n\r\n\r\nprint(re.search(r'a.*d', 'abc123DEF')) # 결과 없음(None)\r\nNone\r\n\r\n\r\n# a 그리고 모든 문자 중 0개 이상 포함하고 다음 D인 문자열\r\nresult = re.search(r'a.*D', 'abc123DEF')\r\nstart, end = result.span()\r\nprint(start, end) # 위치\r\n0 7\r\nprint(result.string) # 해당 문자열\r\nabc123DEF\r\n\r\nre.IGNORECASE(또는 re.I)를 지정하면 대소문자를 무시한다.\r\n\r\nm1 = re.search(r'a.*d', 'abc123DEF')\r\nm2 = re.search(r'a.*d', 'abc123DEF', re.I)\r\nprint(m1) #none\r\nNone\r\nprint(m2)\r\n<re.Match object; span=(0, 7), match='abc123D'>\r\n\r\nmatch객체의 group()을 통해 일치한 값을 추출 할 수 있다.\r\n\r\nm = re.search(r'a(.*)(c)', 'abc123DEF')\r\nm.group(0) # 일치된 모든 값\r\n'abc'\r\nm.group(1) # 정규표현식에서 첫번째 괄호 일치 값\r\n'b'\r\nm.group(2) # 두번째 괄호 일치 값\r\n'c'\r\n\r\nre.findall() 함수는 정규표현식에 맞는 모든 부분을 추출한다.\r\n\r\n#영숫자 문자나 언더바가 2~3개로 이어진 문자열.\r\nre.findall(r'\\w{2,3}', 'This is pen')\r\n['Thi', 'is', 'pen']\r\n\r\nre.sub() 함수는 정규표현시에 매칭되는 문자열 치환한다.\r\nre.sub(정규표현식, replace, stirng)\r\n\r\n#영숫자 문자나 언더바가 4개로 이어진 문자열.\r\n#정규표현식에 맞는 문자열을 That으로 바꾼다.\r\nre.sub(r'\\w{4}', 'That', 'This is a pen')\r\n'That is a pen'\r\n\r\nmatch() : 시작되는 문자열이 정규표현식과 일치하는지 확인.\r\nsearch() : 문자열 내에서 정규표현식과 일치하는 부분을 확인.\r\n\r\nresult = re.match(r'a.*c', ' abc123DEF') # 시작부분에 빈칸\r\nprint(result)\r\nNone\r\n\r\n\r\nresult = re.search(r'a.*c', ' abc123DEF')\r\nprint(result)\r\n<re.Match object; span=(1, 4), match='abc'>\r\n\r\n정규표현식으로 스크레이핑\r\n목표 : 정규표현식으로 전체도서목록 책이름과 url 추출하기.\r\n\r\n# html 추출.\r\nfrom urllib.request import urlopen\r\nimport sys\r\nf = urlopen('https://www.hanbit.co.kr/store/books/full_book_list.html')\r\nhtml = f.read().decode('utf-8')\r\n\r\nhtml자료를 html변수에 저장한다.\r\n크롬에서 F12를 누르면 html의 elements를 볼 수 있다. 전체도서목록에서\r\n도서제목과 url이 나열되있는 부분을 찾는다.\r\n\r\nfrom html import unescape\r\n# re.findall() 메서드를 통해 도서 하나에 해당하는 HTML을 추출\r\nfor partial_html in re.findall(r'<td class=\"left\"><a.*?<\/td>', html, re.DOTALL):\r\n    # 도서의 URL을 추출\r\n    url = re.search(r'<a href=\"(.*?)\">', partial_html).group(1)\r\n    url = 'http://www.hanbit.co.kr' + url\r\n    # 태그를 제거해서 도서의 제목을 추출\r\n    title = re.sub(r'<.*?>', '', partial_html)\r\n    title = unescape(title)\r\n    print('url:', url)\r\n    print('title:', title)\r\n    print('---')\r\nurl: http://www.hanbit.co.kr/store/books/look.php?p_code=B7422209817\r\ntitle: 변화하는 세계 질서\r\n---\r\nurl: http://www.hanbit.co.kr/store/books/look.php?p_code=B2317469552\r\ntitle: 혼자 공부하는 얄팍한 코딩 지식\r\n---\r\nurl: http://www.hanbit.co.kr/store/books/look.php?p_code=B7975223427\r\ntitle: 때려치우기의 기술\r\n---\r\nurl: http://www.hanbit.co.kr/store/books/look.php?p_code=B9882279606\r\ntitle: 완성된 웹사이트로 배우는 HTML&CSS 웹 디자인\r\n---\r\nurl: http://www.hanbit.co.kr/store/books/look.php?p_code=B6334451644\r\ntitle: 실무자를 위한 그래프 데이터 활용법\r\n---\r\nurl: http://www.hanbit.co.kr/store/books/look.php?p_code=B1207366943\r\ntitle: 구글 엔지니어는 이렇게 일한다\r\n---\r\nurl: http://www.hanbit.co.kr/store/books/look.php?p_code=B4597837371\r\ntitle: 리얼 국내여행 2022~2023(개정판)\r\n---\r\nurl: http://www.hanbit.co.kr/store/books/look.php?p_code=B2885456605\r\ntitle: 벌레가 되어도 출근은 해야 해\r\n---\r\nurl: http://www.hanbit.co.kr/store/books/look.php?p_code=B3346434043\r\ntitle: 일잘러의 비밀, 엑셀 대신 파이썬으로 업무 자동화하기\r\n---\r\nurl: http://www.hanbit.co.kr/store/books/look.php?p_code=B6493543959\r\ntitle: 리얼 제주 [2022~2023년 최신판]\r\n---\r\nurl: http://www.hanbit.co.kr/store/books/look.php?p_code=B7170139829\r\ntitle: STEM@CookBook, 공학 기초수학(2판)\r\n---\r\nurl: http://www.hanbit.co.kr/store/books/look.php?p_code=B9103889809\r\ntitle: 똑똑한 두뇌 연습 : 300개 미로찾기\r\n---\r\nurl: http://www.hanbit.co.kr/store/books/look.php?p_code=B6446476778\r\ntitle: 엑셀, R, 파이썬으로 시작하는 데이터 분석\r\n---\r\nurl: http://www.hanbit.co.kr/store/books/look.php?p_code=B1913587019\r\ntitle: MLOps 도입 가이드\r\n---\r\nurl: http://www.hanbit.co.kr/store/books/look.php?p_code=B2831223974\r\ntitle: 엑셀이 편해지는 파이썬\r\n---\r\nurl: http://www.hanbit.co.kr/store/books/look.php?p_code=B3180984708\r\ntitle: 올림포스 연대기\r\n---\r\nurl: http://www.hanbit.co.kr/store/books/look.php?p_code=B2949290774\r\ntitle: 쉽게 배우는 AWS AI 서비스\r\n---\r\nurl: http://www.hanbit.co.kr/store/books/look.php?p_code=B9483006177\r\ntitle: 상식적으로 상식을 배우는 법\r\n---\r\nurl: http://www.hanbit.co.kr/store/books/look.php?p_code=B8613567974\r\ntitle: 엑셀로 부자되기\r\n---\r\nurl: http://www.hanbit.co.kr/store/books/look.php?p_code=B1519857692\r\ntitle: 저는 해외주식투자가 처음인데요\r\n---\r\nurl: http://www.hanbit.co.kr/store/books/look.php?p_code=B7550382130\r\ntitle: 데이터 익명화를 위한 파이프라인\r\n---\r\nurl: http://www.hanbit.co.kr/store/books/look.php?p_code=B5725043400\r\ntitle: XGBoost와 사이킷런을 활용한 그레이디언트 부스팅\r\n---\r\nurl: http://www.hanbit.co.kr/store/books/look.php?p_code=B9078925849\r\ntitle: 동시성 프로그래밍\r\n---\r\nurl: http://www.hanbit.co.kr/store/books/look.php?p_code=B9856488100\r\ntitle: 우리 고양이, 이럴 땐 어떡하지?\r\n---\r\nurl: http://www.hanbit.co.kr/store/books/look.php?p_code=B5392144310\r\ntitle: 케라스로 구현하는 딥러닝\r\n---\r\nurl: http://www.hanbit.co.kr/store/books/look.php?p_code=B5658376953\r\ntitle: 엄마가 만드는 초등 수학 자신감\r\n---\r\nurl: http://www.hanbit.co.kr/store/books/look.php?p_code=B2027701371\r\ntitle: 파이썬을 활용한 금융 분석(2판)\r\n---\r\nurl: http://www.hanbit.co.kr/store/books/look.php?p_code=B3855421165\r\ntitle: 유연한 소프트웨어를 만드는 설계 원칙\r\n---\r\nurl: http://www.hanbit.co.kr/store/books/look.php?p_code=B5151815130\r\ntitle: 대통령의 숙제\r\n---\r\nurl: http://www.hanbit.co.kr/store/books/look.php?p_code=B2707221826\r\ntitle: 맛있는 디자인 애프터 이펙트 CC 2022\r\n---\r\nurl: http://www.hanbit.co.kr/store/books/look.php?p_code=B7121664936\r\ntitle: STEM@CookBook, Beer의 정역학과 재료역학(3판)\r\n---\r\nurl: http://www.hanbit.co.kr/store/books/look.php?p_code=B7790361118\r\ntitle: 3일 만에 끝내는 초등 글쓰기 트레이닝 북\r\n---\r\nurl: http://www.hanbit.co.kr/store/books/look.php?p_code=B4309942517\r\ntitle: 도메인 주도 개발 시작하기\r\n---\r\nurl: http://www.hanbit.co.kr/store/books/look.php?p_code=B6236324381\r\ntitle: STEIN 푸리에 해석학\r\n---\r\nurl: http://www.hanbit.co.kr/store/books/look.php?p_code=B1102492805\r\ntitle: 뛰지 마라, 지친다\r\n---\r\nurl: http://www.hanbit.co.kr/store/books/look.php?p_code=B5538841948\r\ntitle: 맛있는 디자인 프리미어 프로 CC 2022\r\n---\r\nurl: http://www.hanbit.co.kr/store/books/look.php?p_code=B6113501223\r\ntitle: 헤드 퍼스트 디자인 패턴(개정판)\r\n---\r\nurl: http://www.hanbit.co.kr/store/books/look.php?p_code=B2277305433\r\ntitle: 세금의 세계사\r\n---\r\nurl: http://www.hanbit.co.kr/store/books/look.php?p_code=B5471282287\r\ntitle: 시맨틱 데이터 모형화\r\n---\r\nurl: http://www.hanbit.co.kr/store/books/look.php?p_code=B4355310473\r\ntitle: 찐 UXer가 알려주는 UX/UI 실무 가이드\r\n---\r\nurl: http://www.hanbit.co.kr/store/books/look.php?p_code=B5732906061\r\ntitle: 처음 배우는 엘릭서 프로그래밍\r\n---\r\nurl: http://www.hanbit.co.kr/store/books/look.php?p_code=B7239224234\r\ntitle: 고객을 끌어오는 구글 애널리틱스4\r\n---\r\nurl: http://www.hanbit.co.kr/store/books/look.php?p_code=B2761632078\r\ntitle: 자바 마이크로서비스를 활용한 SRE\r\n---\r\nurl: http://www.hanbit.co.kr/store/books/look.php?p_code=B9202577080\r\ntitle: 머신러닝 실무 프로젝트(2판)\r\n---\r\nurl: http://www.hanbit.co.kr/store/books/look.php?p_code=B2736769991\r\ntitle: 쏙쏙 한글 깨치기 1단계 듣기∙읽기\r\n---\r\nurl: http://www.hanbit.co.kr/store/books/look.php?p_code=B1793194115\r\ntitle: 쏙쏙 한글 깨치기 1단계 만들기∙쓰기\r\n---\r\nurl: http://www.hanbit.co.kr/store/books/look.php?p_code=B7678436157\r\ntitle: 쏙쏙 한글 깨치기 1단계 말놀이 동시\r\n---\r\nurl: http://www.hanbit.co.kr/store/books/look.php?p_code=B2733383112\r\ntitle: 쏙쏙 한글 깨치기 1단계 세트(받침 없는 글자)\r\n---\r\nurl: http://www.hanbit.co.kr/store/books/look.php?p_code=B5654917817\r\ntitle: 쏙쏙 한글 깨치기 2단계 듣기∙읽기\r\n---\r\nurl: http://www.hanbit.co.kr/store/books/look.php?p_code=B6791524292\r\ntitle: 쏙쏙 한글 깨치기 2단계 만들기∙쓰기\r\n---\r\n\r\nre.DOTALL은 정규표현식에서 “.”에 줄바꿈문자를 포함한 모든 문자와\r\n매치한다는 의미이다.\r\nhtml.unescape()함수는 html에서 escape된 문자열을 unescape해주는\r\n함수이다. 위 예를 들면,\r\n\r\nlist = re.findall(r'<td class=\"left\"><a.*?<\/td>', html, re.DOTALL)\r\ntitle1 = re.sub(r'<.*?>', '', list[5])\r\nprint(\"escape:\", title1)\r\nescape: 구글 엔지니어는 이렇게 일한다\r\ntitle2 = unescape(title1)\r\nprint(\"unescape:\", title2)\r\nunescape: 구글 엔지니어는 이렇게 일한다\r\n\r\n이처럼 “(” -> “(” 로 unecape 됨을 확인할 수 있다.\r\nescape code는 편집기와 브라우저가 헷갈리지 않도록 여러 기호를\r\n표현하는 code이다.\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-07-17-python-crawler2/images/regular.jpg",
    "last_modified": "2022-05-16T00:10:37+09:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-07-12-python-crawler1/",
    "title": "urllib으로 웹페이지 추출",
    "description": "파이썬 urllib.request 모듈을 이용한 웹페이지 추출",
    "author": [
      {
        "name": "nackta",
        "url": {}
      }
    ],
    "date": "2021-07-12",
    "categories": [
      "Python",
      "Crawling"
    ],
    "contents": "\r\n\r\nContents\r\n크롤러란?\r\nurllib으로 웹페이지\r\n추출하기\r\nmeta 태그에서 인코딩\r\n방식 추출법\r\n\r\n크롤러란?\r\n크롤러 : 웹페이지의 하이퍼링크를 순회하면서 웹 페이지를 다운로드 하는\r\n작업\r\n스크레이핑 : 다운로드한 웹페이지에서 필요한 정보를 추출하는 작업\r\nurllib으로 웹페이지 추출하기\r\n\r\nfrom urllib.request import urlopen\r\nimport sys\r\nf = urlopen('https://news.daum.net/breakingnews/economic')\r\n\r\nurlopen() 함수는 URL을 인자로 받아 HTTPResponse 자료형의 객체를\r\n반환한다.\r\n\r\nencoding = f.info().get_content_charset(failobj=\"utf-8\")\r\nprint('encoding:', encoding, file=sys.stderr)\r\nencoding: utf-8\r\n\r\nHTTPResponse의 content-type을 참조하면 인코딩 방식을 알아낼 수\r\n있다.\r\n인코딩 방식이 설정되있지 않다면 자동으로 utf-8을 사용하도록\r\n설정한다.\r\n\r\ntext = f.read().decode(encoding)\r\n# print(text) #너무 길어서 주석처리\r\n\r\n.decode(인코딩방식)을 입력해주면 HTTPResponse에서 bytes 자료형이었던\r\n문자열을 str 자료형으로 디코딩 해준다.\r\nmeta 태그에서 인코딩 방식\r\n추출법\r\nHTTPResponse의 content-type의 정보가 항상 맞지 않는 경우가 있다.\r\n이럴땐 meta태그에서 명시된 인코딩 방식을 추출할 수 있다.\r\n\r\nimport re\r\nf = urlopen('https://news.daum.net/breakingnews/economic')\r\nbytes_content = f.read()\r\n\r\n일단 bytes 자료형을 변수에 저장한다.\r\n\r\nscanned_text = bytes_content[:1024].decode('ascii', errors='replace')\r\n\r\nmeta태그에서 인코딩 방식은 charset=“~”형태로 명시되 있는데 HTML\r\n앞부분에 적혀 있는 경우가 많다. 그래서 1024바이트 부분까지 슬라이싱 하여\r\nascii문자로 디코딩 한다. ascii범위 외 문자는 대체(replace)되어 예외가\r\n없다.\r\n\r\nmatch = re.search(r'charset=[\"\\']?([\\w-]+)', scanned_text)\r\nmatch.group(1)\r\n'utf-8'\r\n\r\n정규 표현식을 통해 charset=값을 추출한다. 확인해보면 utf-8임을 알\r\n수있다.\r\n\r\nif match:\r\n    encoding = match.group(1)\r\nelse:\r\n    encoding = 'utf-8'\r\n    \r\ntext = bytes_content.decode(encoding)\r\n# print(text)\r\n\r\n만약 charset이 명시되지 않았다면 utf-8을 사용한다.\r\nprint(text)를 통해 html형식의 문자열을 확인할 수 있다.\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-07-12-python-crawler1/images/crawling.jpg",
    "last_modified": "2022-05-16T00:01:18+09:00",
    "input_file": {}
  }
]
